{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "52414b32ba2e4addbdbe5fb5157bb705": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66d82b78fdf5408781b3b054e1c96e45",
              "IPY_MODEL_b56e3ef9f29d4b98836d21ee2bece07d",
              "IPY_MODEL_fc202d9c360145ac94fb9fa7adadd863"
            ],
            "layout": "IPY_MODEL_4f577489c85946dca85b48be04f84705"
          }
        },
        "66d82b78fdf5408781b3b054e1c96e45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c500252051f4c539e78f9452d208cda",
            "placeholder": "​",
            "style": "IPY_MODEL_93604c67197b4bbf8bac48cf6089e19c",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b56e3ef9f29d4b98836d21ee2bece07d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89968b430068449ea5d14c634d7adfab",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e6d64455e3b4c1e88e4df73fafd80d3",
            "value": 3
          }
        },
        "fc202d9c360145ac94fb9fa7adadd863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_376bde990f1b4f61b662163f27d9f46c",
            "placeholder": "​",
            "style": "IPY_MODEL_5aaa0ad526b54819ad483a78b87e050d",
            "value": " 3/3 [01:08&lt;00:00, 21.05s/it]"
          }
        },
        "4f577489c85946dca85b48be04f84705": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c500252051f4c539e78f9452d208cda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93604c67197b4bbf8bac48cf6089e19c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89968b430068449ea5d14c634d7adfab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e6d64455e3b4c1e88e4df73fafd80d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "376bde990f1b4f61b662163f27d9f46c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aaa0ad526b54819ad483a78b87e050d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PeterHJY628/Llama3.2-Vision-Finetune/blob/master/DEFT_GaLore.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "md_Fo8mzN-so",
        "outputId": "669313a5-f582-4050-8207-384030b15dd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Created output directories in Google Drive at: /content/drive/MyDrive/surgical_llm_demo\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m119.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.4.0 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.6.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (4.67.1)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=a50026e250330ccb573a1f2d9e0e09be2ae3c1ca23ec353b0246c64a287d1ddb\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n",
            "Downloading model weights...\n",
            "Retrieving folder contents\n",
            "Processing file 1Qem7_KLvEG2FNPPe1yuUAMMlQ4m7s7iR config.json\n",
            "Processing file 1ZEXLryK9AKEwwlLct2rPqFYTLmgmfWn0 generation_config.json\n",
            "Processing file 1WDCSTLPtUmmde0obwnZN-zyvCBZbEQni model-00001-of-00003.safetensors\n",
            "Processing file 1weVvaqGd2duXppPo1vnb9eXZJ03i71TA model-00002-of-00003.safetensors\n",
            "Processing file 1Lql_HcYDuCGq95WIripSwvH31M9jF9j6 model-00003-of-00003.safetensors\n",
            "Processing file 1PpFdNUndciuhZ7q3ko3zo9gviYlgOWOt model.safetensors.index.json\n",
            "Processing file 1lYBf0gaP4PWy5glnGMvRDUXb8ybQFEyb special_tokens_map.json\n",
            "Processing file 1mQVBi2is0DtJks2oC4_9sU7nvarZhxcd tokenizer_config.json\n",
            "Processing file 1sWJmR89LjxYGwGywx6o0kjwDVwED1azk tokenizer.json\n",
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Qem7_KLvEG2FNPPe1yuUAMMlQ4m7s7iR\n",
            "To: /content/drive/MyDrive/surgical_llm_demo/models/DEFT-GaLore_weight/config.json\n",
            "100% 953/953 [00:00<00:00, 5.85MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZEXLryK9AKEwwlLct2rPqFYTLmgmfWn0\n",
            "To: /content/drive/MyDrive/surgical_llm_demo/models/DEFT-GaLore_weight/generation_config.json\n",
            "100% 184/184 [00:00<00:00, 887kB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1WDCSTLPtUmmde0obwnZN-zyvCBZbEQni\n",
            "From (redirected): https://drive.google.com/uc?id=1WDCSTLPtUmmde0obwnZN-zyvCBZbEQni&confirm=t&uuid=ea169807-45f1-44b6-bb92-2304d0c7e398\n",
            "To: /content/drive/MyDrive/surgical_llm_demo/models/DEFT-GaLore_weight/model-00001-of-00003.safetensors\n",
            "100% 5.00G/5.00G [01:15<00:00, 65.9MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1weVvaqGd2duXppPo1vnb9eXZJ03i71TA\n",
            "From (redirected): https://drive.google.com/uc?id=1weVvaqGd2duXppPo1vnb9eXZJ03i71TA&confirm=t&uuid=5dcd4746-001e-498a-980f-e2be81ae8fe6\n",
            "To: /content/drive/MyDrive/surgical_llm_demo/models/DEFT-GaLore_weight/model-00002-of-00003.safetensors\n",
            "100% 4.93G/4.93G [01:13<00:00, 67.6MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1Lql_HcYDuCGq95WIripSwvH31M9jF9j6\n",
            "From (redirected): https://drive.google.com/uc?id=1Lql_HcYDuCGq95WIripSwvH31M9jF9j6&confirm=t&uuid=94e93435-98d4-4caf-bf7f-e3d858973bd6\n",
            "To: /content/drive/MyDrive/surgical_llm_demo/models/DEFT-GaLore_weight/model-00003-of-00003.safetensors\n",
            "100% 2.92G/2.92G [01:01<00:00, 47.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PpFdNUndciuhZ7q3ko3zo9gviYlgOWOt\n",
            "To: /content/drive/MyDrive/surgical_llm_demo/models/DEFT-GaLore_weight/model.safetensors.index.json\n",
            "100% 20.9k/20.9k [00:00<00:00, 78.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1lYBf0gaP4PWy5glnGMvRDUXb8ybQFEyb\n",
            "To: /content/drive/MyDrive/surgical_llm_demo/models/DEFT-GaLore_weight/special_tokens_map.json\n",
            "100% 325/325 [00:00<00:00, 2.11MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1mQVBi2is0DtJks2oC4_9sU7nvarZhxcd\n",
            "To: /content/drive/MyDrive/surgical_llm_demo/models/DEFT-GaLore_weight/tokenizer_config.json\n",
            "100% 54.6k/54.6k [00:00<00:00, 3.35MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1sWJmR89LjxYGwGywx6o0kjwDVwED1azk\n",
            "To: /content/drive/MyDrive/surgical_llm_demo/models/DEFT-GaLore_weight/tokenizer.json\n",
            "100% 17.2M/17.2M [00:00<00:00, 48.0MB/s]\n",
            "Download completed\n",
            "Model weights downloaded to /content/drive/MyDrive/surgical_llm_demo/models/\n",
            "Downloading datasets...\n",
            "Surgical-VQA_V.csv already exists\n",
            "Overlaying_V.csv already exists\n",
            "Segment-MRI_V.csv already exists\n",
            "Segment-Video_V.csv already exists\n",
            "Detect-Instrument_V.csv already exists\n",
            "2model_V.csv already exists\n",
            "3model_V.csv already exists\n"
          ]
        }
      ],
      "source": [
        "# Surgical LLM Agent Demo\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create output directories in Google Drive\n",
        "import os\n",
        "output_base_dir = '/content/drive/MyDrive/surgical_llm_demo'\n",
        "model_dir = f'{output_base_dir}/models/'\n",
        "data_dir = f'{output_base_dir}/datasets'\n",
        "results_dir = f'{output_base_dir}/results'\n",
        "metrics_dir = f'{output_base_dir}/metrics'\n",
        "\n",
        "# Create directories if they don't exist\n",
        "for directory in [output_base_dir, model_dir, data_dir, results_dir, metrics_dir]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "print(f\"Created output directories in Google Drive at: {output_base_dir}\")\n",
        "\n",
        "# Install required packages\n",
        "!pip install -q transformers==4.45.1 datasets==3.0.1 evaluate==0.4.3 gdown nltk torch==2.4.0 torchvision==0.19.0\n",
        "!pip install -q huggingface_hub\n",
        "!pip install -q bitsandbytes>=0.43.2\n",
        "!pip install -q accelerate\n",
        "!pip install rouge_score\n",
        "\n",
        "# Download necessary NLTK data\n",
        "import nltk\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('punkt', quiet=True)\n",
        "\n",
        "# Download model weights using gdown (NOTE: Replace with your actual file ID)\n",
        "print(\"Downloading model weights...\")\n",
        "MODEL_FILE_ID = \"1l5tJ41cQa0M8z0UF8Az96DX1sZMAV0Yt\"  # Replace with the actual file ID from Google Drive\n",
        "#https://drive.google.com/drive/folders/1c6dLqsDnivVClRBdzfeZbd4HvLkIEfah?usp=drive_link\n",
        "#https://drive.google.com/drive/folders/1l5tJ41cQa0M8z0UF8Az96DX1sZMAV0Yt?usp=sharing\n",
        "\n",
        "# Check if model is already downloaded\n",
        "if not os.path.exists(f\"{model_dir}/config.json\"):\n",
        "    !gdown --folder {MODEL_FILE_ID} -O {model_dir}\n",
        "    print(f\"Model weights downloaded to {model_dir}\")\n",
        "else:\n",
        "    print(f\"Model weights already exist at {model_dir}\")\n",
        "\n",
        "# Download datasets\n",
        "print(\"Downloading datasets...\")\n",
        "DATASET_FILE_IDS = {\n",
        "    \"Surgical-VQA_V.csv\": \"1rjv3PzKHqz5BjJn8anR2jSwNTPS2k0Ak\",\n",
        "    \"Overlaying_V.csv\": \"1gFpt8kjoc0kzTBXXiRlYgwDC-HzlSGAr\",\n",
        "    \"Segment-MRI_V.csv\": \"1rSJfPEqg24fhk4MybqpRw652orLfgojc\",\n",
        "    \"Segment-Video_V.csv\": \"1lo0xEKcJgMPy0T0AXfRIjNbrSdJyrXkR\",\n",
        "    \"Detect-Instrument_V.csv\": \"1A4c5ieW6P_oqMnWRybl6NmtmTshsPX1n\",\n",
        "    \"2model_V.csv\": \"1dl_81gH1o06ZYLn1FuL8J4INxq3cLqnu\",\n",
        "    \"3model_V.csv\": \"1WwLigg0kjRHyxkOaSYc8V2M8GFK9qlc9\"\n",
        "}\n",
        "\n",
        "# https://drive.google.com/file/d/1rjv3PzKHqz5BjJn8anR2jSwNTPS2k0Ak/view?usp=drive_link\n",
        "# https://drive.google.com/file/d/1gFpt8kjoc0kzTBXXiRlYgwDC-HzlSGAr/view?usp=drive_link\n",
        "# https://drive.google.com/file/d/1rSJfPEqg24fhk4MybqpRw652orLfgojc/view?usp=drive_link\n",
        "# https://drive.google.com/file/d/1lo0xEKcJgMPy0T0AXfRIjNbrSdJyrXkR/view?usp=drive_link\n",
        "# https://drive.google.com/file/d/1A4c5ieW6P_oqMnWRybl6NmtmTshsPX1n/view?usp=drive_link\n",
        "# https://drive.google.com/file/d/1dl_81gH1o06ZYLn1FuL8J4INxq3cLqnu/view?usp=drive_link\n",
        "# https://drive.google.com/file/d/1WwLigg0kjRHyxkOaSYc8V2M8GFK9qlc9/view?usp=drive_link\n",
        "\n",
        "# Download each dataset\n",
        "for filename, file_id in DATASET_FILE_IDS.items():\n",
        "    if not os.path.exists(f\"{data_dir}/{filename}\"):\n",
        "        !gdown {file_id} -O {data_dir}/{filename}\n",
        "        print(f\"Downloaded {filename}\")\n",
        "    else:\n",
        "        print(f\"{filename} already exists\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Fuctions"
      ],
      "metadata": {
        "id": "ii0pdy3jOJ71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import torch\n",
        "import pandas as pd\n",
        "import re\n",
        "import evaluate\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from tqdm.notebook import tqdm\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# ---------------------------- Utility Function ----------------------------\n",
        "def generate_SM(que: str) -> str:\n",
        "    return (\n",
        "        \"You are a surgical AI agent assisting in pituitary surgery. Your job is to handle surgeons' queries efficiently by choosing appropriate text-promptable AI models and generating corresponding prompts.\\n\"\n",
        "        \"Available models: Segment-Video, Segment-MRI, Track-Instrument, Surgical-VQA, Overlaying.\\n\"\n",
        "        \"Question: {que}\\n\"\n",
        "        \"- Use ONE model if query focuses on a single, simple aspect:\\n\"\n",
        "        \"Example (single-model):\\n\"\n",
        "        \"Model: Segment-Video\\nPrompt: Segment the sella in the video.\\n\"\n",
        "        \"- Use MULTIPLE models if query requires several types of information:\\n\"\n",
        "        \"Example (multi-model):\\n\"\n",
        "        \"Step1:\\nModel: Segment-MRI\\nPrompt: Segment the pituitary tumor from MRI.\\n\"\n",
        "        \"Step2:\\nModel: Segment-Video\\nPrompt: Segment the sella in the video.\\n\"\n",
        "        \"Now, follow the same format to answer the provided question—no extra text, labels, or formatting.\"\n",
        "    ).format(que=que)\n",
        "\n",
        "def generate_answer(question, model, tokenizer):\n",
        "    model.eval()\n",
        "    question = generate_SM(question)\n",
        "    input_text = f\"Query:\\n{question}\\nResponse:\\n\"\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=2048).to(model.device)\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(**inputs, max_new_tokens=200, pad_token_id=tokenizer.eos_token_id)\n",
        "    answer = tokenizer.decode(output[0], skip_special_tokens=True).split(\"Response:\\n\")[-1].strip()\n",
        "    return answer\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2SiZuvOsOLxQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inference"
      ],
      "metadata": {
        "id": "4cpn5t7iOQHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_dir = f'{model_dir}/DEFT-GaLore_weight'\n",
        "\n",
        "# Load the model using BitsAndBytes for efficient loading\n",
        "print(\"Loading model...\")\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "try:\n",
        "    # Load model and tokenizer\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_dir,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_dir, use_fast=False)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    print(\"Model loaded successfully!\")\n",
        "\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {str(e)}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "id": "_-xgtBZPORzF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "52414b32ba2e4addbdbe5fb5157bb705",
            "66d82b78fdf5408781b3b054e1c96e45",
            "b56e3ef9f29d4b98836d21ee2bece07d",
            "fc202d9c360145ac94fb9fa7adadd863",
            "4f577489c85946dca85b48be04f84705",
            "6c500252051f4c539e78f9452d208cda",
            "93604c67197b4bbf8bac48cf6089e19c",
            "89968b430068449ea5d14c634d7adfab",
            "2e6d64455e3b4c1e88e4df73fafd80d3",
            "376bde990f1b4f61b662163f27d9f46c",
            "5aaa0ad526b54819ad483a78b87e050d"
          ]
        },
        "outputId": "8c58c792-fc26-4dd0-d95c-7d0efee9f905"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52414b32ba2e4addbdbe5fb5157bb705"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Input question\n",
        "# Single model case:\n",
        "print(\"The question of single model case is:\\nCan you show me where to be careful and not make incisions?\\n\")\n",
        "# Define the sample query question here:\n",
        "question1 = \"Can you show me where to be careful and not make incisions?\"\n",
        "\n",
        "answer1 = generate_answer(question1, model, tokenizer)\n",
        "print(\"The answer generated by agent is:\")\n",
        "print(answer1)\n",
        "\n",
        "# Multiple model case:\n",
        "print(\"\\nThe question of multiple models case is:\\nIdentift if I'm prepared to transition to tumor excision with the pituitary rongeur?\\n\")\n",
        "question2 = \"Identift if I'm prepared to transition to tumor excision with the pituitary rongeur?\"\n",
        "\n",
        "answer2 = generate_answer(question2, model, tokenizer)\n",
        "print(\"The answer generated by agent is:\")\n",
        "print(answer2)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkmjUPd2EFeY",
        "outputId": "55c8139c-c769-4360-b55d-d3eec1be46d6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The question of single model case is:\n",
            "Can you show me where to be careful and not make incisions?\n",
            "\n",
            "The answer generated by agent is:\n",
            "Model: Segment-Video\n",
            "Prompt: Segment the internal skull structures.\n",
            "\n",
            "The question of multiple models case is:\n",
            "Identift if I'm prepared to transition to tumor excision with the pituitary rongeur?\n",
            "\n",
            "The answer generated by agent is:\n",
            "Step1:\n",
            "Model: Track-Instrument\n",
            "Prompt: Verify the presence and correct positioning of the pituitary rongeur.\n",
            "Step2:\n",
            "Model: Surgical-VQA\n",
            "Prompt: Confirm readiness for the tumour excision step and briefly recommend the next instrument if needed.\n"
          ]
        }
      ]
    }
  ]
}